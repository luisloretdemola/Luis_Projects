{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "import snowflake.connector\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function from your external script\n",
    "from IOS_query import run_snowflake_query\n",
    "\n",
    "# Run the query and get the results as a DataFrame\n",
    "ios_df = run_snowflake_query()\n",
    "\n",
    "# Display the DataFrame\n",
    "ios_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function from your external script\n",
    "from district_map_query import map_query\n",
    "\n",
    "# Run the query and get the results as a DataFrame\n",
    "map_df = map_query()\n",
    "map_df = map_df[['ZIP_CODE__C', 'STATE__C', 'STATE_ABBREVIATION__C', 'MSA_MARKET_PRIMARY__C', 'MSA_NUMBER__C', 'MARKETING_DISTRICT__C']]\n",
    "\n",
    "# Display the DataFram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_geo_map = map_df.isna().mean() * 100\n",
    "\n",
    "print(\"Columns in IOs_filtered with missing values:\")\n",
    "print(missing_geo_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ios_df))\n",
    "print(len(map_df))\n",
    "\n",
    "merged_df = pd.merge(ios_df, map_df, left_on='BILLINGZIP', right_on = 'ZIP_CODE__C', how='inner')\n",
    "\n",
    "\n",
    "\n",
    "print(len(merged_df))\n",
    "\n",
    "print(f'loss is {1-len(merged_df)/len(ios_df)}')\n",
    "\n",
    "# Convert the column to date format with specified format\n",
    "merged_df['IO_DATE'] = pd.to_datetime(merged_df['IO_DATE'], format='%Y-%m-%d')\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datetime import date\n",
    "\n",
    "# today = date.today()\n",
    "\n",
    "# # Convert to datetime and round to the start of the month\n",
    "# today_month_start = pd.to_datetime(today).to_period('M').to_timestamp()\n",
    "\n",
    "# # Convert back to string in yyyy-mm-dd format\n",
    "# end_date = today_month_start.strftime('%Y-%m-%d')\n",
    "\n",
    "# print(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['IO_DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datetime\n",
    "#merged_df[\"IO_DATE\"] = pd.to_datetime(merged_df[\"IO_DATE\"], errors=\"coerce\")\n",
    "# Add a 'year_month' column to group by month\n",
    "merged_df[\"year_month\"] = merged_df[\"IO_DATE\"].dt.to_period('M')\n",
    "# Convert to datetime and round to the start of the month\n",
    "#merged_df['check'] = merged_df[\"year_month\"].to_period('M').to_timestamp()\n",
    "\n",
    "# Convert back to string in yyyy-mm-dd format\n",
    "#end_date = today_month_start.strftime('%Y-%m-%d')\n",
    "\n",
    "#merged_df[\"year_month\"] = merged_df[\"IO_DATE\"].dt.to_period(\"M\").to_timestamp()\n",
    "print(merged_df[\"IO_DATE\"])\n",
    "\n",
    "# Aggregate by month, with multiple aggregations\n",
    "monthly_aggregated = (\n",
    "    merged_df.groupby(\n",
    "        [\"year_month\", \"STATE__C\", \"STATE_ABBREVIATION__C\", \"MSA_MARKET_PRIMARY__C\"]\n",
    "    )\n",
    "    .agg(\n",
    "        io_count=(\"IOS\", \"nunique\"),  # Count rows per month\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_aggregated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Parameters\n",
    "\n",
    "\n",
    "# MSA_MARKET = \"New York\"\n",
    "# #STATE = \"New York\"\n",
    "# BRAND_MSA = \"New York, NY\"\n",
    "\n",
    "# BRAND_MSA_list = [\"Austin, TX\", \"Denver, CO\", \"Los Angeles, CA\", \"Miami-Ft. Lauderdale, FL\", \n",
    "#                   \"New York, NY\", \"San Francisco-Oakland-San Jose, CA\"]\n",
    "\n",
    "# # Used as contains filter \n",
    "# MSA_MARKET_list = [\"Austin\", \"Denver\", \"Los Angeles\", \"Miami\", \"New York\", \"San Francisco\"]\n",
    "\n",
    "# Used as equals filter\n",
    "city_to_state = {\n",
    "    \"Austin\": \"Texas\",\n",
    "    \"Denver\": \"Colorado\",\n",
    "    \"Los Angeles\": \"California\",\n",
    "    \"Miami\": \"Florida\",\n",
    "    \"New York\": \"New York\",\n",
    "    \"San Francisco\": \"California\"\n",
    "    \n",
    "}\n",
    "\n",
    "STATE = city_to_state[MSA_MARKET]\n",
    "\n",
    "print('the state is ' + STATE)\n",
    "\n",
    "#intervention_date = '2024-08-01'\n",
    "\n",
    "campaign_start_dict = {'Austin, TX': '2024-09-09', 'Denver, CO': '2024-08-19', \\\n",
    "    'Los Angeles, CA': '2024-09-02', 'Miami-Ft. Lauderdale, FL': '2024-08-26',\\\n",
    "    'New York, NY': '2024-08-26', 'San Francisco-Oakland-San Jose, CA': '2024-09-02',\\\n",
    "    'Queens_New York': '2024-08-26', 'Brooklyn_New York': '2024-08-26',\\\n",
    "    'The Bronx_New York': '2024-08-26', 'Jersey City_New Jersey': '2024-08-26',\\\n",
    "    'Newark_New Jersey': '2024-08-26', 'San Jose_California': '2024-09-02'\n",
    "    }\n",
    "\n",
    "\n",
    "# Convert to datetime and round to the start of the month\n",
    "month_start = pd.to_datetime(campaign_start_dict[BRAND_MSA]).to_period('M').to_timestamp()\n",
    "\n",
    "# Convert back to string in yyyy-mm-dd format\n",
    "intervention_date = month_start.strftime('%Y-%m-%d')\n",
    "\n",
    "print(intervention_date)\n",
    "#date_start = campaign_start_dict[treatment_city_region]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_monthly_data = monthly_aggregated[\n",
    "    monthly_aggregated[\"MSA_MARKET_PRIMARY__C\"].str.contains(MSA_MARKET, case=False)\n",
    "    & (monthly_aggregated[\"STATE__C\"] == STATE)\n",
    "    #& (monthly_aggregated[\"year_month\"] >= '2022')\n",
    "].sort_values(by=\"year_month\", ascending=True)\n",
    "\n",
    "city_monthly_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_monthly_data[\"year_month\"] = city_monthly_data[\"year_month\"].dt.to_timestamp()\n",
    "city_monthly_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from datetime import date\n",
    "\n",
    "\n",
    "\n",
    "print(intervention_date)\n",
    "\n",
    "marketing_pre_period = city_monthly_data[\n",
    "    city_monthly_data[\"year_month\"] < intervention_date\n",
    "][[\"year_month\", \"io_count\"]]\n",
    "\n",
    "today = dt.date.today()\n",
    "\n",
    "# # Convert to datetime and round to the start of the month\n",
    "today_month_start = pd.to_datetime(today).to_period('M').to_timestamp()\n",
    "\n",
    "# # Convert back to string in yyyy-mm-dd format\n",
    "treatment_end_date = today_month_start.strftime('%Y-%m-%d')\n",
    "\n",
    "print(treatment_end_date)\n",
    "\n",
    "\n",
    "marketing_post_period = city_monthly_data[\n",
    "    (city_monthly_data[\"year_month\"]\n",
    "    >= intervention_date) & (city_monthly_data[\"year_month\"]\n",
    "    < treatment_end_date)\n",
    "][[\"year_month\", \"io_count\"]]\n",
    "\n",
    "marketing_pre_period.head()\n",
    "\n",
    "# ['2010-02-05','2012-06-29']\n",
    "\n",
    "\n",
    "# marketing_post_period.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = city_monthly_data[['year_month', 'io_count']]\n",
    "# Convert the date column to datetime (if it's not already)\n",
    "df_final['year_month'] = pd.to_datetime(df_final['year_month'])  # Adjust column name if necessary\n",
    "\n",
    "# Set the date column as the index\n",
    "df_final.set_index('year_month', inplace=True)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(marketing_post_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data\n",
    "#intervention_date = '2024-08-01'\n",
    "data = pd.concat([marketing_pre_period, marketing_post_period])\n",
    "data[\"intervention\"] = data[\"year_month\"] >= pd.to_datetime(intervention_date)\n",
    "data[\"t\"]=range(len(data))\n",
    "data['month'] = data['year_month'].dt.month\n",
    "\n",
    "data_final = data.set_index('year_month')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function from your external script\n",
    "from direct_search_query import run_direct_search_query\n",
    "\n",
    "# Run the query and get the results as a DataFrame\n",
    "#direct_search_df = run_direct_search_query('New York', 'New York')\n",
    "direct_search_df = run_direct_search_query(MSA_MARKET, STATE)\n",
    "\n",
    "# Display the DataFrame\n",
    "direct_search_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function from your external script\n",
    "from brand_search_query import run_brand_search_query\n",
    "\n",
    "# Run the query and get the results as a DataFrame\n",
    "print(MSA_MARKET)\n",
    "print(STATE)\n",
    "print(BRAND_MSA)\n",
    "\n",
    "brand_search_df = run_brand_search_query()\n",
    "\n",
    "brand_search_df = brand_search_df[(brand_search_df['METRO'] == BRAND_MSA) & (brand_search_df['REGION'] == STATE)]\n",
    "\n",
    "# Display the DataFrame\n",
    "brand_search_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reset = data_final.reset_index()\n",
    "data_reset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join DataFrames\n",
    "\n",
    "# Convert column to datetime\n",
    "data_reset['year_month'] = pd.to_datetime(data_reset['year_month'])\n",
    "direct_search_df['MONTH_START'] = pd.to_datetime(direct_search_df['MONTH_START'])\n",
    "\n",
    "df_merge_1 = pd.merge(data_reset, direct_search_df, left_on = 'year_month', \\\n",
    "    right_on = 'MONTH_START', \\\n",
    "    how = 'inner')\n",
    "\n",
    "df_merge_1 = df_merge_1.rename(columns={'MONTH_START': 'direct_month_start', 'MONTHLY_SUM': 'direct_search_sum'})\n",
    "df_merge_1 = df_merge_1.drop(columns = 'MARKETING_CHANNEL')\n",
    "\n",
    "df_merge_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_search_df['MONTH_START'] = pd.to_datetime(brand_search_df['MONTH_START'])\n",
    "\n",
    "df_merge_2 = pd.merge(df_merge_1, brand_search_df, left_on = 'direct_month_start', \\\n",
    "    right_on = 'MONTH_START', \\\n",
    "    how = 'inner')\n",
    "\n",
    "df_merge_2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['CITY', 'REGION_x', 'COUNTRY', 'direct_month_start', 'STATE', 'REGION_y', 'METRO', 'MONTH_START']\n",
    "\n",
    "df_final2 = df_merge_2.drop(columns = columns_to_drop)\n",
    "df_final2 = df_final2.set_index('year_month')\n",
    "df_final2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2['direct_search_sum'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2 = df_final2[df_final2['direct_search_sum'] > 2]\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_series = df_final2.reset_index()\n",
    "\n",
    "# Plot the time series\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_series['year_month'], df_series['SPEND'], marker='o')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(f'{MSA_MARKET} Paid Search Spend Over Time', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Value', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(fname = f'{MSA_MARKET} Paid Search Over Time')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series\n",
    "#plt.plot(df_series['io_count'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.plot(df_series['year_month'], df_series['io_count'], marker='o')\n",
    "plt.title('IO Time Series Plot', fontsize = 22)\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('IO Count', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.savefig(fname = f'{MSA_MARKET} IOs Over Time ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(df_series['io_count'])\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "# Plot autocorrelation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_acf(df_series['io_count'], lags=20)  # Specify number of lags\n",
    "plt.title('io_count Autocorrelation Plot', fontsize=16)\n",
    "plt.xlabel('Lag', fontsize=14)\n",
    "plt.ylabel('Autocorrelation', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import ccf\n",
    "\n",
    "# Compute cross-correlation between two features\n",
    "cross_corr = ccf(df_series['io_count'], df_series['SPEND'])\n",
    "\n",
    "# Plot the cross-correlation\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(cross_corr)), cross_corr)\n",
    "plt.title('Cross-Correlation Between io count and spend')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Cross-Correlation')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding lags\n",
    "df_final2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "df_final3 = df_final2.copy()\n",
    "df_final3['lag_SPEND'] = df_final3['SPEND'].shift(k)\n",
    "df_final3['lag_direct_search_sum'] = df_final3['direct_search_sum'].shift(k)\n",
    "df_final3['lag_IMPRESSIONS'] = df_final3['IMPRESSIONS'].shift(k)\n",
    "df_final3['lag_io_count'] = df_final3['io_count'].shift(k)\n",
    "df_final3 = df_final3.dropna()\n",
    "df_final3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import causalpy as cp\n",
    "\n",
    "seed=42\n",
    "result4 = cp.InterruptedTimeSeries(\n",
    "    data=df_final3,\n",
    "    treatment_time=pd.Timestamp(intervention_date),\n",
    "    formula=\"io_count ~ 1 + t + C(month) + direct_search_sum + SPEND + IMPRESSIONS + \\\n",
    "         + lag_io_count\",\n",
    "    model=cp.pymc_models.LinearRegression(sample_kwargs={\"random_seed\": seed}),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, ax = result4.plot()\n",
    "\n",
    "# Adjust the figure size\n",
    "fig4.set_size_inches(12, 8)  # Example: Width = 12 inches, Height = 8 inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "\n",
    "fig4.savefig(f\"{MSA_MARKET}_causal_impact_plot.png\")\n",
    "plt.close()  # Close the figure to avoid overwriting\n",
    "print(f\"Causal Graph for {MSA_MARKET} saved as {MSA_MARKET}_plot.png\")\n",
    "plt.axis('off')  # Turn off axes for better visualization\n",
    "# img = mpimg.imread(f\"{MSA_MARKET}_plot.png\")#\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all attributes and methods of the model object\n",
    "print(dir(result4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pred_samples = result4.pre_pred.posterior_predictive[\"y_hat\"]\n",
    "print(pre_pred_samples)  # Check the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean prediction across posterior samples\n",
    "pre_pred_mean = pre_pred_samples.mean(dim=\"draw\")\n",
    "pre_pred_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "az.summary(result4.post_impact.max(\"obs_ind\"))\n",
    "az.summary(result4.pre_pred.posterior_predictive[\"y_hat\"].mean(\"obs_ind\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(result4.post_impact.max(\"obs_ind\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index of the final time point\n",
    "index_4 = result4.post_impact_cumulative.obs_ind.max()\n",
    "# grab the posterior distribution of the cumulative impact at this final time point\n",
    "last_cumulative_estimate_4 = result4.post_impact_cumulative.sel({\"obs_ind\": index_4})\n",
    "# get summary stats\n",
    "az.summary(last_cumulative_estimate_4, hdi_prob=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Inputs\n",
    "estimate = 56.046\n",
    "lower_ci = 19.697\n",
    "upper_ci = 93.348\n",
    "z_critical = 1.645  # For a 90% confidence interval\n",
    "\n",
    "# Calculate standard error\n",
    "se = (upper_ci - lower_ci) / (2 * z_critical)\n",
    "\n",
    "# Calculate z-score\n",
    "z_score = estimate / se\n",
    "\n",
    "# Calculate p-value\n",
    "p_value = 2 * norm.sf(abs(z_score))\n",
    "print(f\"p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get index of the final time point\n",
    "# index_4 = result4.post_impact_cumulative.obs_ind.max()\n",
    "# # grab the posterior distribution of the cumulative impact at this final time point\n",
    "# last_cumulative_estimate_4 = result4.post_impact_cumulative.sel({\"obs_ind\": index_4})\n",
    "# # get summary stats\n",
    "# az.summary(last_cumulative_estimate_4, hdi_prob=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of intervention periods\n",
    "int_periods = df_series['intervention'].sum()\n",
    "\n",
    "#rows with intervention\n",
    "intervention_df = df_series.tail(int_periods)\n",
    "\n",
    "int_dates = intervention_df[['year_month', 'io_count']].reset_index(drop=True)\n",
    "int_dates['treatment_region'] = MSA_MARKET\n",
    "# Add a column with the index number\n",
    "int_dates['Index_Number'] = int_dates.index\n",
    "\n",
    "int_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_dates.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int_periods):\n",
    "    if i ==0:\n",
    "        az_df = pd.DataFrame(az.summary(result4.post_impact.sel({\"obs_ind\": i}), hdi_prob=0.9))\n",
    "    else:\n",
    "\n",
    "        # Concatenate the row to the DataFrame\n",
    "        #df = pd.concat([df, new_row], ignore_index=True)\n",
    "        new_row = pd.DataFrame(az.summary(result4.post_impact.sel({\"obs_ind\": i}), hdi_prob = 0.9))\n",
    "        az_df = pd.concat([az_df, new_row], ignore_index=True)\n",
    "        #az_df.concat(pd.DataFrame(az.summary(result4.post_impact.sel({\"obs_ind\": i}))))\n",
    "\n",
    "az_df['Index_Number'] = az_df.index\n",
    "az_df['bayes_Stat_Sig'] = (~((az_df['hdi_5%'] < 0 )| (az_df['hdi_95%'] < 0)))\n",
    "az_df.head()\n",
    "\n",
    "az_join = pd.merge(int_dates, az_df, on = 'Index_Number', how = 'inner')\n",
    "az_join['counter_io_count'] = az_join['io_count'] - az_join['mean']\n",
    "az_join['perc_lift'] = round((az_join['io_count'] - az_join['counter_io_count'])/az_join['counter_io_count'], 4)\n",
    "\n",
    "az_final = az_join[['Index_Number', 'year_month', 'treatment_region', 'io_count', \\\n",
    "    'counter_io_count', 'mean', 'sd','perc_lift', 'bayes_Stat_Sig', 'hdi_5%', 'hdi_95%','mcse_mean', 'mcse_sd' ]]\n",
    "\n",
    "az_final =az_final.rename(columns = {'mean': 'bayes_uplift'})\n",
    "az_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with the index column\n",
    "az_final.to_csv(f\"{MSA_MARKET}_monthly_uplift.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index of the final time point\n",
    "index_4 = result4.post_impact_cumulative.obs_ind.max()\n",
    "# grab the posterior distribution of the cumulative impact at this final time point\n",
    "last_cumulative_estimate_4 = result4.post_impact_cumulative.sel({\"obs_ind\": index_4})\n",
    "# get summary stats\n",
    "az.summary(last_cumulative_estimate_4, hdi_prob=0.9)\n",
    "\n",
    "az_cumulative = az.summary(last_cumulative_estimate_4, hdi_prob=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = int_dates.agg(\n",
    "    treatment_start = (\"year_month\", \"min\"),\n",
    "    treatment_end = (\"year_month\", \"max\"),\n",
    "    io_sum = (\"io_count\", \"sum\")\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_dates['io_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_cumulative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust the cumulative table\n",
    "\n",
    "#az_cumulative['Index_Number'] = az_df.index\n",
    "az_cumulative['bayes_Stat_Sig'] = (~((az_cumulative['hdi_5%'] < 0 )| (az_cumulative['hdi_95%'] < 0)))\n",
    "#az_cumulative.head()\n",
    "az_cumulative['io_sum'] = int_dates['io_count'].sum()\n",
    "az_cumulative['counter_io_sum'] = az_final['counter_io_count'].sum()\n",
    "az_cumulative['treatment_region'] = MSA_MARKET\n",
    "az_cumulative['treatment_start'] = int_dates['year_month'].min()\n",
    "az_cumulative['treatment_end'] = int_dates['year_month'].max()\n",
    "#az_cumulative_join = pd.merge(az_cumulative_final, az_cumulative, on = 'Index_Number', how = 'inner')\n",
    "\n",
    "#az_cumulative['counter_io_count'] = az_cumulative_join['io_count'] - az_join['mean']\n",
    "az_cumulative['perc_lift'] = round((az_cumulative['io_sum'] - \\\n",
    "    az_cumulative['counter_io_sum'])/az_cumulative['counter_io_sum'], 4)\n",
    "\n",
    "az_cumulative_final = az_cumulative[['treatment_region', 'treatment_start', 'treatment_end', \\\n",
    "    'io_sum', 'counter_io_sum', 'mean', 'sd','perc_lift', 'bayes_Stat_Sig', 'hdi_5%', 'hdi_95%','mcse_mean', 'mcse_sd' ]]\n",
    "\n",
    "az_cumulative_final =az_cumulative_final.rename(columns = {'mean': 'bayes_uplift'})\n",
    "az_cumulative_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with the index column\n",
    "az_cumulative_final.to_csv(f\"{MSA_MARKET}_cumulative_uplift.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
